{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ ActualizaciÃ³n Recaudo PSE\n",
    "## Desarrollado por David Paez Ingeniero de datos\n",
    "## Fecha de actualizacion 19/06/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Lista de festivos (2025 y 2026) ---\n",
    "FESTIVOS = {\n",
    "    # 2025\n",
    "    date(2025, 1, 1), date(2025, 1, 6), date(2025, 3, 24), date(2025, 4, 17), date(2025, 4, 18),\n",
    "    date(2025, 5, 1), date(2025, 6, 2), date(2025, 6, 23), date(2025, 6, 30), date(2025, 7, 20),\n",
    "    date(2025, 8, 7), date(2025, 8, 18), date(2025, 10, 13), date(2025, 11, 3), date(2025, 11, 17),\n",
    "    date(2025, 12, 8), date(2025, 12, 25),\n",
    "    # 2026\n",
    "    date(2026, 1, 1), date(2026, 1, 12), date(2026, 3, 23), date(2026, 4, 2), date(2026, 4, 3),\n",
    "    date(2026, 5, 1), date(2026, 5, 18), date(2026, 6, 8), date(2026, 6, 15), date(2026, 6, 29),\n",
    "    date(2026, 7, 20), date(2026, 8, 7), date(2026, 8, 17), date(2026, 10, 12), date(2026, 11, 2),\n",
    "    date(2026, 11, 16), date(2026, 12, 8), date(2026, 12, 25),\n",
    "}\n",
    "\n",
    "# --- FunciÃ³n para obtener el primer dÃ­a hÃ¡bil del mes ---\n",
    "def primer_dia_habil_del_mes(hoy: date, festivos: set) -> date:\n",
    "    primer = date(hoy.year, hoy.month, 1)\n",
    "    while primer.weekday() >= 5 or primer in festivos:\n",
    "        primer += timedelta(days=1)\n",
    "    return primer\n",
    "\n",
    "# --- Evaluar si hoy es ese primer dÃ­a hÃ¡bil ---\n",
    "hoy = date.today()\n",
    "primer_habil = primer_dia_habil_del_mes(hoy, FESTIVOS)\n",
    "\n",
    "if hoy == primer_habil:\n",
    "    print(f\"âœ… Hoy ({hoy}) es el primer dÃ­a hÃ¡bil del mes. Ejecutando proceso...\")\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    ## Extraccion\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # ========================\n",
    "    # #  CALCULO DE FECHAS SQL PARA EXTRAER EL PRIMER DIA DEL MES ANTERIOR Y ACTUAL\n",
    "    # ========================\n",
    "    inicio_mes_actual = hoy.replace(day=1)\n",
    "    inicio_mes_anterior = (inicio_mes_actual - timedelta(days=1)).replace(day=1)\n",
    "    fecha_inicio = inicio_mes_anterior.strftime('%Y-%m-%d')\n",
    "    fecha_fin = inicio_mes_actual.strftime('%Y-%m-%d')\n",
    "\n",
    "    # ConexiÃ³n a df1\n",
    "    server = 'fabogsqlclu,1433'\n",
    "    database = 'GestionCliente'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "    # Consulta SQL con parÃ¡metros\n",
    "    query = \"\"\"\n",
    "    SELECT C.Fechapago, C.HORPAG, C.MINPAG, C.TIPO_PRODUCTO,\n",
    "           C.CFLNME AS Tipo_subproducto, C.CUX1AP, C.NUMDOC,\n",
    "           C.CODSUC, C.NUMCRE, C.NOMCLI AS Nombre_Cliente,\n",
    "           C.NUCREX, C.ORIPAG AS Origen_pago,\n",
    "           CASE \n",
    "               WHEN ORIPAG = 1 THEN 'Conavi'\n",
    "               WHEN ORIPAG = 2 THEN 'Banco caja social'\n",
    "               WHEN ORIPAG = 3 THEN 'Banco de BogotÃ¡'\n",
    "               WHEN ORIPAG = 4 THEN 'Citibank'\n",
    "               WHEN ORIPAG = 5 THEN 'Banco de occidente'\n",
    "               WHEN ORIPAG = 6 THEN 'PSE'\n",
    "               WHEN ORIPAG = 7 THEN 'Finazauto'\n",
    "               WHEN ORIPAG = 8 THEN 'Bancolombia'\n",
    "               WHEN ORIPAG = 10 THEN 'Banco de occidente ACH'\n",
    "               WHEN ORIPAG = 11 THEN 'Banco AV Villas'\n",
    "               WHEN ORIPAG = 12 THEN 'Cenit'\n",
    "               WHEN ORIPAG = 13 THEN 'Banco Davivienda'\n",
    "               WHEN ORIPAG = 14 THEN 'Cpv - Avvillas'\n",
    "               WHEN ORIPAG = 15 THEN 'Libranza - Davivienda'\n",
    "               WHEN ORIPAG = 16 THEN 'Sudameris'\n",
    "               WHEN ORIPAG = 17 THEN 'DÃ©bito AutomÃ¡tico'\n",
    "               WHEN ORIPAG = 19 THEN 'Ws Bancolombia'\n",
    "               WHEN ORIPAG IN (30, 31, 32) THEN 'Cajas Depositarias'\n",
    "               WHEN ORIPAG = 63 THEN 'Cajas Finandina (Cheque TDC)'\n",
    "               WHEN ORIPAG = 64 THEN 'Banca LÃ­nea - Finandina (TDC)'\n",
    "               WHEN ORIPAG = 65 THEN 'Banco Finandina Pago TDC Dirigido'\n",
    "               WHEN ORIPAG = 66 THEN 'Banco Finandina Pago Alterno TDC'\n",
    "               ELSE NULL \n",
    "           END AS Descripcion_origen_pago,\n",
    "           C.FORPAG AS Forma_pago, C.VLRPAG AS Valor_pagado,\n",
    "           C.CIUREC, C.DESOBS, C.CODAPL\n",
    "    FROM (\n",
    "        SELECT CONCAT(SUBSTRING(B.FECPAG1,1,4), '-', SUBSTRING(B.FECPAG1,5,2), '-', SUBSTRING(B.FECPAG1,7,2)) AS Fechapago, B.*\n",
    "        FROM (\n",
    "            SELECT \n",
    "                CASE \n",
    "                    WHEN a.CUX1AP IN (50, 51, 53, 33, 30) THEN 'CREDITO'\n",
    "                    WHEN a.CUX1AP = 20 THEN 'AHORRO'\n",
    "                    WHEN a.CUX1AP IS NULL AND LEN(a.NUCREX) IN (5, 6, 15, 16) THEN 'TDC'\n",
    "                    WHEN a.CUX1AP IS NULL AND LEFT(a.NUMCRE,1) = '4' THEN 'TDC'\n",
    "                    WHEN a.CUX1AP IS NULL AND LEN(a.NUCREX) = 10 THEN 'CREDITO'\n",
    "                    WHEN LEN(a.NUMCRE) = 16 AND LEFT(a.NUMCRE,1) = '4' THEN 'TDC'\n",
    "                    WHEN a.CUX1AP IS NULL AND LEN(a.NUMCRE) = 16 THEN 'CREDITO'\n",
    "                    ELSE 'NULL'\n",
    "                END AS TIPO_PRODUCTO,\n",
    "                CAST(FECPAG AS varchar) AS FECPAG1,\n",
    "                A.*\n",
    "            FROM OPENQUERY(DB2400_182, \n",
    "                'SELECT IFNULL(c.numdoc, cc.CUSSNR) AS numdoc,\n",
    "                        CXP.CUX1AP,\n",
    "                        pcl.*,\n",
    "                        TP.CFLNME\n",
    "                 FROM bnkprd01.pagcncl pcl\n",
    "                 LEFT JOIN inttarcre.sattarjet t ON t.pan = pcl.nucrex\n",
    "                 LEFT JOIN inttarcre.SATBENEFI b ON b.cuenta = t.cuenta\n",
    "                 LEFT JOIN inttarcre.SATDACOPE c ON c.identcli = b.identcli\n",
    "                 LEFT JOIN BNKPRD01.LNP00301 CR ON CR.LNNOTE = pcl.nucrex\n",
    "                 LEFT JOIN BNKPRD01.CFP503 TP ON TP.CFTYP = CR.LNTYPE\n",
    "                 LEFT JOIN BNKPRD01.CUP009 CXP ON CR.LNNOTE = CXP.CUX1AC\n",
    "                 LEFT JOIN BNKPRD01.CUP00301 Cc ON Cc.CUNBR = CXP.CUX1CS\n",
    "                 WHERE pcl.fecpag >= ''20250501'' AND pcl.fecpag < ''20250601'''\n",
    "            ) A\n",
    "        ) B\n",
    "    ) C\n",
    "    WHERE C.Fechapago >= ? AND C.Fechapago < ?\n",
    "    \"\"\"\n",
    "\n",
    "    # ConexiÃ³n y ejecuciÃ³n\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    df1 = pd.read_sql(query, conn, params=(fecha_inicio, fecha_fin))\n",
    "    conn.close()\n",
    "    # Conexion a df2\n",
    "    #df2 es el mismo df5\n",
    "    server = 'fabogriesgo\\riesgodb,1433'  # Nota: doble barra y puerto separado por coma\n",
    "    database = 'Productos y transaccionalidad'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    # Crear cadena de conexiÃ³n\n",
    "    conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "    # Conectar a la base de datos \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    # Consulta SQL ProductoActivo\n",
    "    query1 = \"\"\"SELECT * FROM [Productos y transaccionalidad].[dbo].[ProductoActivo]\"\"\"\n",
    "    # Ejecutar consulta y guardar resultado en DataFrame\n",
    "    df2 = pd.read_sql(query1, conn)\n",
    "    # Cerrar la conexiÃ³n \n",
    "    conn.close()\n",
    "    # Conexion a df3\n",
    "    server = 'fabogsqlclu,1433'  # Nota: doble barra y puerto separado por coma\n",
    "    database = 'PSE'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    # Crear cadena de conexiÃ³n\n",
    "    conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "    # Conectar a la base de datos \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    # Consulta SQL ProductoActivo\n",
    "    query2 = \"\"\"SELECT * FROM fabogsqlclu.[PSE].[dbo].[TransactionsInfo]\"\"\"\n",
    "    # Ejecutar consulta y guardar resultado en DataFrame\n",
    "    df3 = pd.read_sql(query2, conn)\n",
    "    # Cerrar la conexiÃ³n \n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "    # Conexion a df4\n",
    "    server = 'fabogsqlclu,1433'  # Nota: doble barra y puerto separado por coma\n",
    "    database = 'PSE'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    # Crear cadena de conexiÃ³n\n",
    "    conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "    # Conectar a la base de datos \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    # Consulta SQL ProductoActivo\n",
    "    query3 = \"\"\"Select * ,CASE WHEN LEN(DBNROPRD) >= 11 THEN 'TDC' ELSE 'CREDITO' END AS 'TIPO_PRODUCTO' \n",
    "    from openquery (DB2400_182,'select * from INTERFACES.DBAUTCENF where DBCODRTA = ''OK'' AND DBVLRDEB > 0')\"\"\"\n",
    "    # Ejecutar consulta y guardar resultado en DataFrame\n",
    "    df4 = pd.read_sql(query3, conn)\n",
    "    # Cerrar la conexiÃ³n \n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "    #Conexion a df6\n",
    "    server = 'fabogcubox,1433'  # Nota: doble barra y puerto separado por coma\n",
    "    database = 'Finandina_Cartera'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    # Crear cadena de conexiÃ³n\n",
    "    conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "    # Conectar a la base de datos \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    # Consulta SQL ProductoActivo\n",
    "    query4 = \"\"\"SELECT Nid, [Celular1], [Celular2], [Email1], [Email2] FROM fabogcubox.[Finandina_cartera].dbo.[011 BaseSegmentacionDinamica 201911>]\"\"\"\n",
    "    # Ejecutar consulta y guardar resultado en DataFrame\n",
    "    df6 = pd.read_sql(query4, conn)\n",
    "    # Cerrar la conexiÃ³n \n",
    "    conn.close()\n",
    " \n",
    " \n",
    "    #Conexion a df7\n",
    "    server = 'fabogcubox,1433'  # Nota: doble barra y puerto separado por coma\n",
    "    database = 'Finandina_Cartera'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    # Crear cadena de conexiÃ³n\n",
    "    conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "    # Conectar a la base de datos \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    # Consulta SQL ProductoActivo\n",
    "    query5 = \"\"\"Select * from openquery (DB2400_182,'select CUNA3,CUSSNR from bnkprd01.cup003')\"\"\"\n",
    "    # Ejecutar consulta y guardar resultado en DataFrame\n",
    "    df7 = pd.read_sql(query5, conn)\n",
    "    # Cerrar la conexiÃ³n \n",
    "    conn.close()\n",
    "    #Copia para df5\n",
    "    df5=df2.copy()\n",
    "    # Resultados df1\n",
    "    print(df1.head())\n",
    "    # Resultados df2 Y df5\n",
    "    print(df2.head())\n",
    "    # Resultados df3\n",
    "    print(df3.head())\n",
    "    # Resultados df4\n",
    "    print(df4.head())\n",
    "    # Resultados df5\n",
    "    print(df5.head())\n",
    "    # Resultados df6\n",
    "    print(df6.head())\n",
    "    # Resultados df7\n",
    "    print(df7.head())\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    ## Transformacion\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    ## Carga\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "else:\n",
    "    print(f\"â¸ï¸ Hoy ({hoy}) NO es el primer dÃ­a hÃ¡bil del mes ({primer_habil}). No se ejecuta nada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# CALCULO DE FECHAS SQL PARA EXTRAER EL PRIMER DIA DEL MES ANTERIOR Y ACTUAL\n",
    "# ========================\n",
    "\n",
    "inicio_mes_actual = hoy.replace(day=1)\n",
    "inicio_mes_anterior = (inicio_mes_actual - timedelta(days=1)).replace(day=1)\n",
    "\n",
    "fecha_inicio = inicio_mes_anterior.strftime('%Y-%m-%d')\n",
    "fecha_fin = inicio_mes_actual.strftime('%Y-%m-%d')\n",
    "\n",
    "fecha_inicio_yyyymmdd = inicio_mes_anterior.strftime('%Y%m%d')\n",
    "fecha_fin_yyyymmdd = inicio_mes_actual.strftime('%Y%m%d')\n",
    "\n",
    "# ConexiÃ³n a df1\n",
    "server = 'fabogcubox,1433'  # Nota: puerto separado por coma\n",
    "database = 'Finandina_Cartera'\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Consulta SQL con fechas interpoladas\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    C.Fechapago, C.HORPAG, C.MINPAG, C.TIPO_PRODUCTO,\n",
    "    C.CFLNME AS Tipo_subproducto, C.CUX1AP, C.NUMDOC,\n",
    "    C.CODSUC, C.NUMCRE, C.NOMCLI AS Nombre_Cliente,\n",
    "    C.NUCREX, C.ORIPAG AS Origen_pago,\n",
    "    CASE \n",
    "        WHEN ORIPAG = 1 THEN 'Conavi'\n",
    "        WHEN ORIPAG = 2 THEN 'Banco caja social'\n",
    "        WHEN ORIPAG = 3 THEN 'Banco de BogotÃ¡'\n",
    "        WHEN ORIPAG = 4 THEN 'Citibank'\n",
    "        WHEN ORIPAG = 5 THEN 'Banco de occidente'\n",
    "        WHEN ORIPAG = 6 THEN 'PSE'\n",
    "        WHEN ORIPAG = 7 THEN 'Finazauto'\n",
    "        WHEN ORIPAG = 8 THEN 'Bancolombia'\n",
    "        WHEN ORIPAG = 10 THEN 'Banco de occidente ACH'\n",
    "        WHEN ORIPAG = 11 THEN 'Banco AV Villas'\n",
    "        WHEN ORIPAG = 12 THEN 'Cenit'\n",
    "        WHEN ORIPAG = 13 THEN 'Banco Davivienda'\n",
    "        WHEN ORIPAG = 14 THEN 'Cpv - Avvillas'\n",
    "        WHEN ORIPAG = 15 THEN 'Libranza - Davivienda'\n",
    "        WHEN ORIPAG = 16 THEN 'Sudameris'\n",
    "        WHEN ORIPAG = 17 THEN 'DÃ©bito AutomÃ¡tico'\n",
    "        WHEN ORIPAG = 19 THEN 'Ws Bancolombia'\n",
    "        WHEN ORIPAG IN (30, 31, 32) THEN 'Cajas Depositarias'\n",
    "        WHEN ORIPAG = 63 THEN 'Cajas Finandina (Cheque TDC)'\n",
    "        WHEN ORIPAG = 64 THEN 'Banca LÃ­nea - Finandina (TDC)'\n",
    "        WHEN ORIPAG = 65 THEN 'Banco Finandina Pago TDC Dirigido'\n",
    "        WHEN ORIPAG = 66 THEN 'Banco Finandina Pago Alterno TDC'\n",
    "        ELSE NULL \n",
    "    END AS Descripcion_origen_pago,\n",
    "    C.FORPAG AS Forma_pago, C.VLRPAG AS Valor_pagado,\n",
    "    C.CIUREC, C.DESOBS, C.CODAPL\n",
    "FROM (\n",
    "    SELECT \n",
    "        CONCAT(\n",
    "            SUBSTRING(B.FECPAG1, 1, 4), '-', \n",
    "            SUBSTRING(B.FECPAG1, 5, 2), '-', \n",
    "            SUBSTRING(B.FECPAG1, 7, 2)\n",
    "        ) AS Fechapago, \n",
    "        B.*\n",
    "    FROM (\n",
    "        SELECT \n",
    "            CASE \n",
    "                WHEN a.CUX1AP IN (50, 51, 53, 33, 30) THEN 'CREDITO'\n",
    "                WHEN a.CUX1AP = 20 THEN 'AHORRO'\n",
    "                WHEN a.CUX1AP IS NULL AND LEN(a.NUCREX) IN (5, 6, 15, 16) THEN 'TDC'\n",
    "                WHEN a.CUX1AP IS NULL AND LEFT(a.NUMCRE, 1) = '4' THEN 'TDC'\n",
    "                WHEN a.CUX1AP IS NULL AND LEN(a.NUCREX) = 10 THEN 'CREDITO'\n",
    "                WHEN LEN(a.NUMCRE) = 16 AND LEFT(a.NUMCRE, 1) = '4' THEN 'TDC'\n",
    "                WHEN a.CUX1AP IS NULL AND LEN(a.NUMCRE) = 16 THEN 'CREDITO'\n",
    "                ELSE 'NULL'\n",
    "            END AS TIPO_PRODUCTO,\n",
    "            CAST(FECPAG AS varchar) AS FECPAG1,\n",
    "            A.*\n",
    "        FROM OPENQUERY(DB2400_182, \n",
    "            'SELECT \n",
    "                IFNULL(c.numdoc, cc.CUSSNR) AS numdoc,\n",
    "                CXP.CUX1AP,\n",
    "                pcl.*,\n",
    "                TP.CFLNME\n",
    "            FROM bnkprd01.pagcncl pcl\n",
    "            LEFT JOIN inttarcre.sattarjet t ON t.pan = pcl.nucrex\n",
    "            LEFT JOIN inttarcre.SATBENEFI b ON b.cuenta = t.cuenta\n",
    "            LEFT JOIN inttarcre.SATDACOPE c ON c.identcli = b.identcli\n",
    "            LEFT JOIN BNKPRD01.LNP00301 CR ON CR.LNNOTE = pcl.nucrex\n",
    "            LEFT JOIN BNKPRD01.CFP503 TP ON TP.CFTYP = CR.LNTYPE\n",
    "            LEFT JOIN BNKPRD01.CUP009 CXP ON CR.LNNOTE = CXP.CUX1AC\n",
    "            LEFT JOIN BNKPRD01.CUP00301 Cc ON Cc.CUNBR = CXP.CUX1CS\n",
    "            WHERE pcl.fecpag >= {fecha_inicio_yyyymmdd} AND pcl.fecpag < {fecha_fin_yyyymmdd}\n",
    "            ') A\n",
    "    ) B\n",
    ") C\n",
    "WHERE C.Fechapago >= '{fecha_inicio}' AND C.Fechapago < '{fecha_fin}'\n",
    "\"\"\"\n",
    "\n",
    "conn = pyodbc.connect(conn_str)\n",
    "df1 = pd.read_sql(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexion a df2 (df2 es el mismo df5)\n",
    "server = 'fabogriesgo\\\\riesgodb,1433'  # Nota: doble barra invertida para escapar la barra\n",
    "database = 'Productos y transaccionalidad'\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Crear cadena de conexiÃ³n\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Conectar a la base de datos\n",
    "conn = pyodbc.connect(conn_str)\n",
    "\n",
    "# Consulta SQL ProductoActivo\n",
    "query1 = \"\"\"SELECT * FROM [Productos y transaccionalidad].[dbo].[ProductoActivo]\"\"\"\n",
    "\n",
    "# Ejecutar consulta y guardar resultado en DataFrame\n",
    "df2 = pd.read_sql(query1, conn)\n",
    "\n",
    "# Cerrar la conexiÃ³n\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n de conexiÃ³n\n",
    "server = 'fabogsqlclu,1433'\n",
    "database = 'PSE'\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Conectar a la base de datos\n",
    "conn = pyodbc.connect(conn_str)\n",
    "\n",
    "# Consulta SQL: datos del aÃ±o actual hasta hoy\n",
    "query2 = \"\"\"\n",
    "SELECT * \n",
    "FROM [PSE].[dbo].[TransactionsInfo]\n",
    "WHERE SoliciteDate >= DATEADD(MONTH, -1, DATEFROMPARTS(YEAR(GETDATE()), MONTH(GETDATE()), 1))\n",
    "  AND SoliciteDate < DATEFROMPARTS(YEAR(GETDATE()), MONTH(GETDATE()), 1)\n",
    "  AND LOWER(TransactionState) = 'ok'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df3 = pd.read_sql(query2, conn)\n",
    "\n",
    "# Cerrar conexiÃ³n\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias estandar\n",
    "import pyodbc  # ConexiÃ³n a bases de datos mediante ODBC (SQL Server, Oracle, etc.)\n",
    "import pandas as pd  # ManipulaciÃ³n y anÃ¡lisis de datos en estructuras como DataFrames (leer CSV, Excel, SQL, etc.)\n",
    "import numpy as np  # Soporte para cÃ¡lculos numÃ©ricos y manejo de arrays/matrices\n",
    "import openpyxl  # Leer y escribir archivos Excel (.xlsx), Ãºtil para automatizaciÃ³n de reportes\n",
    "from openpyxl import load_workbook  # Cargar un archivo de Excel existente para modificarlo\n",
    "from openpyxl.styles import NamedStyle  # Crear estilos personalizados para celdas de Excel (fuentes, bordes, etc.)\n",
    "from openpyxl.utils import get_column_letter  # Convertir nÃºmero de columna a letra (por ejemplo, 1 â†’ 'A')\n",
    "from datetime import date,datetime, timedelta # Trabajar con fechas y horas (obtener fecha actual, calcular diferencias, formatear fechas, etc.)\n",
    "import os  # InteracciÃ³n con el sistema operativo (rutas de archivos, crear carpetas, verificar existencia de archivos, etc.)\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davpae\\AppData\\Local\\Temp\\ipykernel_18096\\3348705013.py:17: DtypeWarning: Columns (10,11,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(ruta_excel3, encoding='latin1')\n"
     ]
    }
   ],
   "source": [
    "#df1\n",
    "# Ruta del archivo CSV\n",
    "ruta_excel1 = r\"C:\\Users\\davpae\\Downloads\\df1.csv\"\n",
    "# Leer el archivo CSV con codificaciÃ³n latin-1\n",
    "df1 = pd.read_csv(ruta_excel1, encoding='latin1')\n",
    "\n",
    "#df2\n",
    "# Ruta del archivo CSV\n",
    "ruta_excel2 = r\"C:\\Users\\davpae\\Downloads\\df2.csv\"\n",
    "# Leer el archivo CSV con codificaciÃ³n latin-1\n",
    "df2 = pd.read_csv(ruta_excel2, encoding='latin1')\n",
    "\n",
    "##df3\n",
    "# Ruta del archivo CSV\n",
    "ruta_excel3 = r\"C:\\Users\\davpae\\Downloads\\df3.csv\"\n",
    "# Leer el archivo CSV con codificaciÃ³n latin-1\n",
    "df3 = pd.read_csv(ruta_excel3, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMBIAR A LONG INT64\n",
    "df1['NUMDOC'] = pd.to_numeric(df1['NUMDOC'], errors='coerce').astype('Int64')  # Int64 permite nulos\n",
    "df1['NUCREX'] = pd.to_numeric(df1['NUCREX'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Excluir de las filas de NUMDOC bajo el patrÃ³n 800149923\n",
    "df8 = df1.copy()\n",
    "df10 = df8.loc[df8['NUMDOC'].astype(str).str.contains('800149923')]\n",
    "df9 = df1.loc[~df1['NUMDOC'].astype(str).str.contains('800149923')]\n",
    "\n",
    "# ConversiÃ³n de tipos en df2\n",
    "df2['Obligacion'] = pd.to_numeric(df2['Obligacion'], errors='coerce').astype('Int64')\n",
    "df2['DocumentoCliente'] = pd.to_numeric(df2['DocumentoCliente'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Merge left de quienes contienen 800149923 con df2\n",
    "df11 = df10.merge(\n",
    "    df2,\n",
    "    how='left',\n",
    "    left_on='NUCREX',\n",
    "    right_on='Obligacion'\n",
    ")\n",
    "\n",
    "# Regla: si NUMDOC es igual a DocumentoCliente, se asigna 1\n",
    "df11['NUMDOC'] = df11.apply(\n",
    "    lambda row: 1 if row['NUMDOC'] == row['DocumentoCliente'] else row['NUMDOC'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Column filter\n",
    "orden_columnas = [\n",
    "    'Fechapago', 'HORPAG', 'MINPAG', 'TIPO_PRODUCTO', 'Tipo_subproducto', 'CUX1AP',\n",
    "    'NUMDOC', 'CODSUC', 'NUMCRE', 'Nombre_Cliente', 'Origen_pago',\n",
    "    'Descripcion_origen_pago', 'Forma_pago', 'Valor_pagado', 'CIUREC',\n",
    "    'DESOBS', 'CODAPL'\n",
    "]\n",
    "\n",
    "# Filtrar columnas en df11\n",
    "df11 = df11[orden_columnas]\n",
    "\n",
    "# Concatenar df9 con df11 (sin hacer merge)\n",
    "df12 = pd.concat([df9, df11], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# Transformar Fechapago a datetime (aaaa-mm-dd)\n",
    "df12[\"Fechapago\"] = pd.to_datetime(df12[\"Fechapago\"].astype(str).str.strip(), format=\"%Y-%m-%d\", errors=\"coerce\").dt.date\n",
    "\n",
    "# Redondeo de HORPAG y MINPAG a enteros\n",
    "df12['HORPAG'] = df12['HORPAG'].round().astype('Int64')\n",
    "df12['MINPAG'] = df12['MINPAG'].round().astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.columns = df12.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que no haya valores nulos y convertir a string\n",
    "# Filtrar filas donde el valor en TransactionState (en minÃºsculas) sea exactamente 'ok'\n",
    "df3 = df3[df3['TransactionState'].str.contains(\"OK\",case=False,na=False)]\n",
    "# convertir a datetime\n",
    "df3['SoliciteDate'] = pd.to_datetime(df3['SoliciteDate'], errors='coerce')\n",
    "# Extraer hora y minuto\n",
    "df3['Hour'] = df3['SoliciteDate'].dt.hour\n",
    "df3['Minute'] = df3['SoliciteDate'].dt.minute\n",
    "#Conversion a aaaa-mm-dd\n",
    "df3['BankProcessDate'] = pd.to_datetime(df3['BankProcessDate'], errors='coerce').dt.date\n",
    "df3['SoliciteDate'] = pd.to_datetime(df3['SoliciteDate'], errors='coerce').dt.date\n",
    "df3['SoliciteDateINI'] = pd.to_datetime(df3['SoliciteDateINI'], errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={\n",
    "    'Reference3': 'NUCREX',\n",
    "    'Reference2': 'NUMDOC',\n",
    "    'SoliciteDate': 'Fechapago',\n",
    "    'AmountValue': 'Valor_pagado', \n",
    "    'Hour': 'HORPAG',\n",
    "    'Minute': 'MINPAG'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Tipos en df12 ===\")\n",
    "print(df12[['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG']].dtypes)\n",
    "\n",
    "print(\"\\n=== Tipos en df3 ===\")\n",
    "print(df3[['Reference3', 'Reference2', 'SoliciteDate', 'AmountValue', 'Hour', 'Minute']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LIMPIEZA GENERAL DE COLUMNAS: nombres sin espacios ---\n",
    "df12.columns = df12.columns.str.strip()\n",
    "df3.columns = df3.columns.str.strip()\n",
    "\n",
    "# --- LIMPIEZA df12 ---\n",
    "df12['NUCREX'] = df12['NUCREX'].astype(str).str.strip()\n",
    "df12['NUMDOC'] = df12['NUMDOC'].astype(str).str.strip()\n",
    "df12['Fechapago'] = pd.to_datetime(df12['Fechapago'].astype(str).str.strip(), errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "df12['Valor_pagado'] = pd.to_numeric(df12['Valor_pagado'].astype(str).str.strip(), errors='coerce').round(2)\n",
    "df12['HORPAG'] = pd.to_numeric(df12['HORPAG'].astype(str).str.strip(), errors='coerce').astype('Int64')\n",
    "df12['MINPAG'] = pd.to_numeric(df12['MINPAG'].astype(str).str.strip(), errors='coerce').astype('Int64')\n",
    "\n",
    "# --- LIMPIEZA df3 ---\n",
    "df3['Reference3'] = df3['Reference3'].astype(str).str.strip()\n",
    "df3['Reference2'] = df3['Reference2'].astype(str).str.strip()\n",
    "df3['SoliciteDate'] = pd.to_datetime(df3['SoliciteDate'].astype(str).str.strip(), errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "df3['AmountValue'] = pd.to_numeric(df3['AmountValue'].astype(str).str.strip(), errors='coerce').round(2)\n",
    "df3['Hour'] = pd.to_numeric(df3['Hour'].astype(str).str.strip(), errors='coerce').astype('Int64')\n",
    "df3['Minute'] = pd.to_numeric(df3['Minute'].astype(str).str.strip(), errors='coerce').astype('Int64')\n",
    "\n",
    "# Redondear monto a 0 decimales\n",
    "df12['Valor_pagado'] = pd.to_numeric(df12['Valor_pagado'], errors='coerce').round(0)\n",
    "df3['AmountValue'] = pd.to_numeric(df3['AmountValue'], errors='coerce').round(0)\n",
    "\n",
    "# Redondear horas y minutos al entero mÃ¡s cercano\n",
    "df12['HORPAG'] = pd.to_numeric(df12['HORPAG'], errors='coerce').round(0).astype('Int64')\n",
    "df12['MINPAG'] = pd.to_numeric(df12['MINPAG'], errors='coerce').round(0).astype('Int64')\n",
    "df3['Hour'] = pd.to_numeric(df3['Hour'], errors='coerce').round(0).astype('Int64')\n",
    "df3['Minute'] = pd.to_numeric(df3['Minute'], errors='coerce').round(0).astype('Int64')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir todos los campos a string antes de concatenar\n",
    "df12['LLAVE'] = (\n",
    "    df12['NUCREX'].astype(str) + '|' +\n",
    "    df12['NUMDOC'].astype(str) + '|' +\n",
    "    df12['Fechapago'].astype(str) + '|' +\n",
    "    df12['Valor_pagado'].astype(str) + '|' +\n",
    "    df12['HORPAG'].astype(str) + '|' +\n",
    "    df12['MINPAG'].astype(str)\n",
    ")\n",
    "\n",
    "df3['LLAVE'] = (\n",
    "    df3['Reference3'].astype(str) + '|' +\n",
    "    df3['Reference2'].astype(str) + '|' +\n",
    "    df3['SoliciteDate'].astype(str) + '|' +\n",
    "    df3['AmountValue'].astype(str) + '|' +\n",
    "    df3['Hour'].astype(str) + '|' +\n",
    "    df3['Minute'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop_duplicates(subset='LLAVE', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG']\n",
    "\n",
    "print(\"Tipos de datos en df12:\")\n",
    "print(df12[columnas].dtypes)\n",
    "#print(\"\\nValores en df12:\")\n",
    "#print(df12[columnas].head())\n",
    "\n",
    "print(\"\\nTipos de datos en df3:\")\n",
    "print(df3[columnas].dtypes)\n",
    "#print(\"\\nValores en df3:\")\n",
    "#print(df3[columnas].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12_pse = df12[df12['Descripcion_origen_pago'].astype(str).str.strip().str.upper() == 'PSE'].copy()\n",
    "df_merge_exacto = df12_pse.merge(\n",
    "    df3,\n",
    "    how='left',\n",
    "    left_on=['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG'],\n",
    "    right_on=['Reference3', 'Reference2', 'SoliciteDate', 'AmountValue', 'Hour', 'Minute'],\n",
    "    indicator=True\n",
    ")\n",
    "df_matched = df_merge_exacto[df_merge_exacto['_merge'] == 'both']\n",
    "print(\"Total matches exactos:\", len(df_matched))  # AquÃ­ deberÃ­as ver 102.749\n",
    "df12_pse_matched = df_matched.copy()\n",
    "df12_pse_matched['CIUREC'] = df12_pse_matched['BankName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df13 = df12.merge(\n",
    "##    df3,\n",
    "#    how='left',\n",
    "#    left_on='LLAVE',\n",
    "##    right_on='LLAVE'\n",
    "#)\n",
    "#df13 = df12.merge(df3, on=['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG'], how='left')\n",
    "\n",
    "\n",
    "# Merge LEFT de df12 con df3 usando las columnas correspondientes\n",
    "df13 = df12.merge(\n",
    "    df3,\n",
    "    how='left',\n",
    "    left_on=['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG'],\n",
    "    right_on=['Reference3', 'Reference2', 'SoliciteDate', 'AmountValue', 'Hour', 'Minute'],\n",
    "    indicator=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df13 = df13.drop_duplicates(\n",
    "#    subset=['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG'],\n",
    "#    keep='last'\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el orden de las columnas deseadas\n",
    "orden_columnas = ['Fechapago', 'HORPAG', 'MINPAG', 'TIPO_PRODUCTO', 'Tipo_subproducto', 'CUX1AP', 'NUMDOC', 'CODSUC', 'NUMCRE', 'Nombre_Cliente', 'NUCREX', 'Origen_pago', 'Descripcion_origen_pago', 'Forma_pago', 'Valor_pagado', 'CIUREC', 'DESOBS', 'CODAPL', 'BankName','Hour','Minute']\n",
    "# Filtrar y organizar el DataFrame segÃºn el orden de columnas\n",
    "df13= df13[orden_columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13['CIUREC'] = np.where(\n",
    "    df13['Descripcion_origen_pago'].astype(str).str.strip().str.upper() == 'PSE',\n",
    "    df13['BankName'],\n",
    "    np.nan  # o '', si prefieres cadena vacÃ­a\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13.to_excel(r'C:\\Users\\davpae\\Downloads\\df13.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12_pse = df12[df12['Descripcion_origen_pago'].astype(str).str.strip().str.upper() == 'PSE']\n",
    "\n",
    "df_pse_merge = df12_pse.merge(\n",
    "    df3,\n",
    "    how='left',\n",
    "    left_on=['NUCREX', 'NUMDOC', 'Fechapago', 'Valor_pagado', 'HORPAG', 'MINPAG'],\n",
    "    right_on=['Reference3', 'Reference2', 'SoliciteDate', 'AmountValue', 'Hour', 'Minute'],\n",
    "    indicator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pse_merge['_merge'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo Excel Leads\n",
    "ruta_excelp1 = r\"C:\\Users\\davpae\\Downloads\\preca2.xlsx\"\n",
    "# Leer el archivo Excel\n",
    "dfp1= pd.read_excel(ruta_excelp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporte_merge_progresivo(df12, df3):\n",
    "    pasos = [\n",
    "        (['NUCREX', 'NUMDOC'], ['Reference3', 'Reference2']),\n",
    "        (['Fechapago'], ['SoliciteDate']),\n",
    "        (['Valor_pagado'], ['AmountValue']),\n",
    "        (['HORPAG'], ['Hour']),\n",
    "        (['MINPAG'], ['Minute'])\n",
    "    ]\n",
    "\n",
    "    left_keys = []\n",
    "    right_keys = []\n",
    "    df_temp = df12.copy()\n",
    "\n",
    "    print(\"ðŸ” INICIO DEL REPORTE PROGRESIVO DE MERGE\")\n",
    "    print(\"Total base df12:\", len(df12))\n",
    "\n",
    "    for i, (lk, rk) in enumerate(pasos, start=1):\n",
    "        left_keys += lk\n",
    "        right_keys += rk\n",
    "\n",
    "        df_merged = df_temp.merge(df3, how='left', left_on=left_keys, right_on=right_keys, indicator=True)\n",
    "        count_both = (df_merged['_merge'] == 'both').sum()\n",
    "\n",
    "        print(f\"Paso {i}: Merge en {left_keys} vs {right_keys}\")\n",
    "        print(f\"âž¡ï¸ Registros que cruzan: {count_both}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Llama a esta funciÃ³n con tus DataFrames ya limpiados\n",
    "# reporte_merge_progresivo(df12, df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporte_merge_progresivo(df12, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo CSV\n",
    "ruta_excelp2 = r\"C:\\Users\\davpae\\Downloads\\preca1.csv\"\n",
    "\n",
    "# Leer el archivo CSV con codificaciÃ³n latin-1\n",
    "dfp2 = pd.read_csv(ruta_excelp2, encoding='latin1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
